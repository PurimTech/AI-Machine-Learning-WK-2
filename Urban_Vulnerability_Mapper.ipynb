{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtLnovx0sM1O",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Urban Vulnerability Mapper\n",
        "SDG 11: Sustainable Cities and Communities\n",
        "\n",
        "This project identifies informal settlements and assesses climate vulnerability\n",
        "to help policymakers prioritize interventions for 1.12 billion people in slums.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"URBAN VULNERABILITY MAPPER - SDG 11\")\n",
        "print(\"Addressing Housing Crisis & Climate Resilience\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# ============================================================================\n",
        "# PART 1: GENERATE SYNTHETIC URBAN SETTLEMENT DATA\n",
        "# ============================================================================\n",
        "# In production, this would use satellite imagery from Sentinel-2 or Google Earth Engine\n",
        "# For this demo, we simulate features extracted from satellite images and sensors\n",
        "\n",
        "def generate_urban_data(n_samples=1000):\n",
        "    \"\"\"\n",
        "    Generate synthetic urban settlement data with features that would be\n",
        "    extracted from satellite imagery and environmental sensors.\n",
        "    \"\"\"\n",
        "\n",
        "    data = {\n",
        "        # Satellite-derived features (normally from CNN feature extraction)\n",
        "        'building_density': np.random.uniform(0.1, 1.0, n_samples),\n",
        "        'roof_material_index': np.random.uniform(0, 1, n_samples),  # 0=informal, 1=formal\n",
        "        'road_access_score': np.random.uniform(0, 1, n_samples),\n",
        "        'vegetation_index': np.random.uniform(0, 1, n_samples),  # NDVI\n",
        "        'settlement_area_sqkm': np.random.uniform(0.01, 5.0, n_samples),\n",
        "\n",
        "        # Climate vulnerability features\n",
        "        'avg_temperature_c': np.random.uniform(20, 40, n_samples),\n",
        "        'flood_risk_score': np.random.uniform(0, 1, n_samples),\n",
        "        'elevation_meters': np.random.uniform(0, 500, n_samples),\n",
        "        'distance_to_water_km': np.random.uniform(0.1, 20, n_samples),\n",
        "\n",
        "        # Infrastructure features\n",
        "        'water_access_score': np.random.uniform(0, 1, n_samples),\n",
        "        'electricity_coverage': np.random.uniform(0, 1, n_samples),\n",
        "        'waste_collection_score': np.random.uniform(0, 1, n_samples),\n",
        "    }\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # Create target variable: informal settlement (1) or formal (0)\n",
        "    # Logic: Low roof material, high density, low infrastructure = informal\n",
        "    informal_probability = (\n",
        "        (1 - df['roof_material_index']) * 0.3 +\n",
        "        df['building_density'] * 0.2 +\n",
        "        (1 - df['water_access_score']) * 0.2 +\n",
        "        (1 - df['road_access_score']) * 0.15 +\n",
        "        (1 - df['electricity_coverage']) * 0.15\n",
        "    )\n",
        "\n",
        "    df['is_informal_settlement'] = (informal_probability > 0.5).astype(int)\n",
        "\n",
        "    # Create vulnerability score (for clustering)\n",
        "    df['climate_vulnerability'] = (\n",
        "        df['flood_risk_score'] * 0.4 +\n",
        "        (df['avg_temperature_c'] - 20) / 20 * 0.3 +\n",
        "        (1 - df['elevation_meters'] / 500) * 0.3\n",
        "    )\n",
        "\n",
        "    return df\n",
        "\n",
        "# Generate data\n",
        "print(\"\\n[1/6] Generating urban settlement data...\")\n",
        "urban_data = generate_urban_data(1000)\n",
        "print(f\"âœ“ Generated {len(urban_data)} settlement samples\")\n",
        "print(f\"âœ“ Informal settlements: {urban_data['is_informal_settlement'].sum()}\")\n",
        "print(f\"âœ“ Formal settlements: {(1-urban_data['is_informal_settlement']).sum()}\")\n",
        "\n",
        "# ============================================================================\n",
        "# PART 2: SUPERVISED LEARNING - INFORMAL SETTLEMENT CLASSIFICATION\n",
        "# ============================================================================\n",
        "print(\"\\n[2/6] Training Informal Settlement Classifier...\")\n",
        "\n",
        "# Prepare features and target\n",
        "feature_cols = ['building_density', 'roof_material_index', 'road_access_score',\n",
        "                'vegetation_index', 'settlement_area_sqkm', 'avg_temperature_c',\n",
        "                'flood_risk_score', 'elevation_meters', 'distance_to_water_km',\n",
        "                'water_access_score', 'electricity_coverage', 'waste_collection_score']\n",
        "\n",
        "X = urban_data[feature_cols]\n",
        "y = urban_data['is_informal_settlement']\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "rf_model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
        "rf_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = rf_model.predict(X_test_scaled)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"âœ“ Model trained successfully\")\n",
        "print(f\"âœ“ Accuracy: {accuracy:.2%}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Formal', 'Informal']))\n",
        "\n",
        "# Feature importance\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': feature_cols,\n",
        "    'importance': rf_model.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(\"\\nTop 5 Important Features:\")\n",
        "print(feature_importance.head().to_string(index=False))\n",
        "\n",
        "# ============================================================================\n",
        "# PART 3: UNSUPERVISED LEARNING - VULNERABILITY CLUSTERING\n",
        "# ============================================================================\n",
        "print(\"\\n[3/6] Clustering Areas by Vulnerability...\")\n",
        "\n",
        "# Select features for clustering\n",
        "cluster_features = ['climate_vulnerability', 'water_access_score',\n",
        "                   'electricity_coverage', 'waste_collection_score',\n",
        "                   'flood_risk_score', 'building_density']\n",
        "\n",
        "X_cluster = urban_data[cluster_features]\n",
        "X_cluster_scaled = StandardScaler().fit_transform(X_cluster)\n",
        "\n",
        "# K-Means clustering\n",
        "kmeans = KMeans(n_clusters=4, random_state=42, n_init=10)\n",
        "urban_data['vulnerability_cluster'] = kmeans.fit_predict(X_cluster_scaled)\n",
        "\n",
        "# Label clusters by priority\n",
        "cluster_summary = urban_data.groupby('vulnerability_cluster').agg({\n",
        "    'climate_vulnerability': 'mean',\n",
        "    'water_access_score': 'mean',\n",
        "    'is_informal_settlement': 'sum'\n",
        "}).round(3)\n",
        "\n",
        "print(\"âœ“ Clustering complete\")\n",
        "print(\"\\nCluster Summary:\")\n",
        "print(cluster_summary)\n",
        "\n",
        "# Assign priority labels\n",
        "priority_map = {\n",
        "    cluster_summary['climate_vulnerability'].idxmax(): 'Critical Priority',\n",
        "    cluster_summary['climate_vulnerability'].idxmin(): 'Low Priority'\n",
        "}\n",
        "\n",
        "# Fill remaining clusters\n",
        "for idx in cluster_summary.index:\n",
        "    if idx not in priority_map:\n",
        "        if cluster_summary.loc[idx, 'climate_vulnerability'] > 0.5:\n",
        "            priority_map[idx] = 'High Priority'\n",
        "        else:\n",
        "            priority_map[idx] = 'Medium Priority'\n",
        "\n",
        "urban_data['priority_level'] = urban_data['vulnerability_cluster'].map(priority_map)\n",
        "\n",
        "# ============================================================================\n",
        "# PART 4: EVALUATION & METRICS\n",
        "# ============================================================================\n",
        "print(\"\\n[4/6] Model Evaluation Metrics...\")\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# Calculate impact metrics\n",
        "total_informal = urban_data['is_informal_settlement'].sum()\n",
        "critical_areas = len(urban_data[urban_data['priority_level'] == 'Critical Priority'])\n",
        "high_priority_informal = len(urban_data[\n",
        "    (urban_data['priority_level'].isin(['Critical Priority', 'High Priority'])) &\n",
        "    (urban_data['is_informal_settlement'] == 1)\n",
        "])\n",
        "\n",
        "print(f\"\\nðŸ“Š IMPACT METRICS:\")\n",
        "print(f\"   â€¢ Total informal settlements identified: {total_informal}\")\n",
        "print(f\"   â€¢ Critical priority areas: {critical_areas}\")\n",
        "print(f\"   â€¢ High-risk informal settlements: {high_priority_informal}\")\n",
        "print(f\"   â€¢ Estimated population affected (assuming 1000/settlement): {total_informal * 1000:,}\")\n",
        "\n",
        "# ============================================================================\n",
        "# PART 5: VISUALIZATION\n",
        "# ============================================================================\n",
        "print(\"\\n[5/6] Generating visualizations...\")\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "fig.suptitle('Urban Vulnerability Mapper - SDG 11 Analysis', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Plot 1: Feature Importance\n",
        "ax1 = axes[0, 0]\n",
        "top_features = feature_importance.head(8)\n",
        "ax1.barh(top_features['feature'], top_features['importance'], color='steelblue')\n",
        "ax1.set_xlabel('Importance Score')\n",
        "ax1.set_title('Top Features for Informal Settlement Detection')\n",
        "ax1.invert_yaxis()\n",
        "\n",
        "# Plot 2: Confusion Matrix\n",
        "ax2 = axes[0, 1]\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax2,\n",
        "            xticklabels=['Formal', 'Informal'],\n",
        "            yticklabels=['Formal', 'Informal'])\n",
        "ax2.set_title(f'Classification Performance (Accuracy: {accuracy:.2%})')\n",
        "ax2.set_ylabel('True Label')\n",
        "ax2.set_xlabel('Predicted Label')\n",
        "\n",
        "# Plot 3: Vulnerability Clusters\n",
        "ax3 = axes[1, 0]\n",
        "scatter = ax3.scatter(urban_data['climate_vulnerability'],\n",
        "                     urban_data['water_access_score'],\n",
        "                     c=urban_data['vulnerability_cluster'],\n",
        "                     cmap='viridis', alpha=0.6, s=50)\n",
        "ax3.set_xlabel('Climate Vulnerability Score')\n",
        "ax3.set_ylabel('Water Access Score')\n",
        "ax3.set_title('Vulnerability Clustering (4 Groups)')\n",
        "plt.colorbar(scatter, ax=ax3, label='Cluster')\n",
        "\n",
        "# Plot 4: Priority Distribution\n",
        "ax4 = axes[1, 1]\n",
        "priority_counts = urban_data['priority_level'].value_counts()\n",
        "colors_priority = {'Critical Priority': '#d62728', 'High Priority': '#ff7f0e',\n",
        "                   'Medium Priority': '#2ca02c', 'Low Priority': '#1f77b4'}\n",
        "ax4.bar(priority_counts.index, priority_counts.values,\n",
        "        color=[colors_priority.get(x, 'gray') for x in priority_counts.index])\n",
        "ax4.set_ylabel('Number of Areas')\n",
        "ax4.set_title('Priority Level Distribution')\n",
        "ax4.tick_params(axis='x', rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('urban_vulnerability_analysis.png', dpi=300, bbox_inches='tight')\n",
        "print(\"âœ“ Saved visualization: urban_vulnerability_analysis.png\")\n",
        "\n",
        "# ============================================================================\n",
        "# PART 6: ETHICAL REFLECTIONS\n",
        "# ============================================================================\n",
        "print(\"\\n[6/6] Ethical Analysis \")\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ETHICAL REFLECTIONS:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "ethical_reflections = \"\"\"\n",
        "\n",
        "1. Data Bias: Use diverse, open-source datasets (UN-Habitat, World Bank) to reduce bias.\n",
        "2. Privacy: All data used is open and anonymized; no personal information.\n",
        "3. Fairness: The model promotes equitable city planning and access to services.\n",
        "4. Sustainability: Encourages evidence-based decisions for resilient infrastructure\n",
        "\"\"\"\n",
        "\n",
        "print(ethical_reflections)"
      ]
    }
  ]
}